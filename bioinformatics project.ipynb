{"cells":[{"cell_type":"markdown","metadata":{"id":"M-w1ENU3Ao_Z"},"source":["# Prvi projekat\n","\n","## Logistika\n","**Projekti se predaju preko github classroom sistema: https://classroom.github.com/a/E77gGtJ6**.\n","\n","Napomene:\n","- Projekat se može raditi individualno ili u paru.\n","- U projektu je potrebno da se nalaze barem:\n","  - .py fajl sa skriptom koja sadrži tražene funkcije i čijim pokretanjem se izvršava celokupna analiza\n","    - Skripta ne mora da prima nikakve argumente (mada bi bilo lepše da se putanje do fajlova prosleđuju prilikom pokretanja, one mogu biti i eksplicitno zapisane (\"hard-kodovane\") u kodu).\n","\n","  - README.md fajl u kojm navesti:\n","    - Imena studenata\n","    - Da li je su urađene sve tačke, i ako nisu šta nije urađeno\n","    - Da li je i na koji način korišćena pomoć AI alata  \n","    (što je dozvoljeno, ali se od studenata očekuje da razumeju i mogu da objasne sve što su dobili kao odgovor)\n","\n","- Podatke (BCF, i TSV fajlove) nemojte dodavati u git repozitorijum! Obzirom na veličinu BCF fajla čak i slučano dodat, pa obrisan fajl će značajno povećati veličinu repozitorijuma i usporiti rad sa njim. Najbolje je na samom početku izrade napraviti .gitignore sa fajlovima u kojima su podaci, ili te fajlove držati izvan direktorijuma gde je kod.\n","\n","- Dodatni fajlovi (Dockerfile, conda requiremnts i slično) se mogu, a ne moraju dodati u repozitorijum.\n","\n","- Zadatak 4 nije neophodno uraditi kako bi se osvojilo svih 20 redovnih bodova. Studenti koji urade taj zadatak mogu na prvom projektu osvojiti više od 20 bodova, ali maksimalan zbir bodova na oba projekta ostaje ograničen na 40 (bonus bodovi služe da nadomeste eventualno izgubljene bodove).\n","\n","\n","## Postavka\n","Dati su fajlovi:\n","- BCF fajl sa čestim mutacijama iz projekta 1000 genoma (`1KG.subset.bcf`)\n","- Fajl sa oznakama fenotipa - zdravi i oboleli (`disease.tsv`)\n","- Fajl sa drugim fenotipskim podacima, gojaznost, pušenje i redovna fizička aktivnost (`env_factors.tsv`)\n","- Tabela ljudskih gena sa koordinatama u referentnom genomu (`entrez.hg38.tsv`)\n","- Tabela biolološkoh procesa sa povezanim genima (`kegg_pathways.tsv`)\n","\n","##Zadaci:\n","\n","1 [4 boda]. Napisati funkciju koja učitava VCF/BCF fajl u pandas Dataframe strukturu, pri čemu su kolone uzorci iz VCF/BCF fajla (jedan uzorak odgovora jednoj osobi), a kolone pozicije u genomu na kojim se nalaze mutacije. Imena kolona treba da budu imena uzoraka preuzeta iz VCF/BCF fajla. Indeks kolonu napraviti od hromozoma i pozicije (na primer u obliku \"\\<hromozom>-\\<pozicija>\"). Ćelije tabele treba da sadrže broj alternativnih alela za dati uzorak na datoj poziciji (0, 1 ili 2) i prema tipu treba da budu uint8. Pozicije koje imaju više od dva alela se preskaču prilikom pravljenja strukture.\n","\n",".\n","\n","2 [4 boda]. Napisati funkciju koja polazeći od pandas Dataframe-a iz zadataka 1 i pandas series objekat koji sadrži status osobe (1 - osoba je zahvaćena, na primer ima bolest, 0 - osoba nije zahvaćena, na primer nema bolest) izvršava GWAS analizu.\n","  - Primeniti hi-kvadrat test sa Laplace-ovom korekcijom (dodavanje 1 na svako polje, kako bi se izbegli problemi sa poljima gde je izbrojano 0 slučajeva).\n","  - Odabrati jedan GWAS model (dominantni, recesivni ili aditivni) i to dokumentovati u okviru funkcije (na primer kroz docstring)\n","  - Poželjno je da funckija interno koristi paralelizaciju (na primer kroz multiprocessing map). Vodite računa o efikasnosti izračunavanja. Za date podatke veoma efikasna implementacija se može završiti u roku od nekoliko minuta, za sproje može potrajati i nekoliko sati. Efikasnost ne utiče na ocenu, ali će dalja izrada i testiranje biti značajno lakši.\n","  - Rezulat funkcije treba da bude pandas Dataframe struktura sa jednom kolonom koja sadrži p vrednosti i indeksom koji je isti kao indeks ulazne Dataframe strukture sa genetskim podacima, sortirana po p vrednosti.\n","  - Funkcija treba da ima logički flag (True/False, podrazumevano True) na osnovu kog se rezultat filtrira tako da sadrži redove gde je p vrednost manja od zadate granične vrednosti, uz primenu Bonferoni korekcije.\n","\n",".\n","\n","3 [4 boda]. Napisati funkciju koja vrši grupisanje mutacija za koje postoji statistički značajna asocijacija, u strukturi iz tačke 3.\n","- Mogući algoritam grupisanja:\n","  - Odrediti kvadrat koeficijent korelacije genotipa za svaki par mutacija. Ukoliko lista `significant` sadrži listu gena mutacija koje hoćemo grupisati, a `genotypes` predstvalja početnu Dataframe strukturu mutacija x uzorak, kvadrat koeficijent korelacije za sve parove možemo odrediti kao:\n","  ```python\n","  np.corrcoef(genotypes[significant].T)**2\n","  ```\n","  - Za svaku mutaciju prolazimo kroz sve do tog trenutka formirane grupe i proveravamo da li je kvadrat koeficijent korelacije između bilo koje mutacije do sada dodate u datu grupu i mutacije koju obrađujemo preko zadate granične vrednosti (za potrebe projekta može se uzeti 0.2) i da li su te dve mutacije fizički dovoljno blizu (na istom hromozomu, i na primer unutar 600,000 baznih parova).\n","  - Ako je uslov zadovoljen za bilo koju mutaciju iz grupe, mutacija koja se obrađuje se dodaju u tu grupu (svaka mutacija može biti u samo jednoj grupi).\n","  - Ako ne postoji grupa kojoj mutacija pripada, formira se nova grupa sa tom mutacijom.\n","  - Rezultat funkcije treba da bude Dataframe struktura sa po jednim redom za svaku grupu i sledećim kolonama:\n","    - Vodeća mutacija (u formatu \"\\<hromozom>-\\<pozicija>\", bira se kao mutacija iz grupe čija je p vrednost najmanja)\n","    - P vrednost vodeće muatcija\n","    - Broj mutacija u hromozomu\n","    - Hromozom (sve mutacije u grupi su uvek na istom hromozomu)\n","    - Najmanja pozcija u grupi\n","    - Najveće pozicija u grupi\n","    - Raspon grupe duž horomozoma (najveća - najmanja pozicija)\n","    - Lista svih mutacija u grupi, u formatu \"\\<hromozom>-\\<pozicija>\"\n","\n",".\n","\n","4 [5 bodova - bonus]. Napraviti i evaluirati Bajesovu mrežu za predviđanje status osobe (zahvaćena / nije zahvaćena) na osnovu:\n","  - Genotipa vodećih mutacija iz prethodnog zadatka. Uzeti najviše 4 grupe sa najmanjim vrednostima vodeće mutacija.\n","  - Drugih fenotipskih podataka, iz dodatnog fajla\n","  - Genotipa vodećih mutacija i drugih fenotipskih podataka\n","- Za svaku od ovih mreža odrediti preciznost, odziv (recall) i tačnost (accuracy)\n","\n",".\n","\n","5 [4 boda]. Identifikovati gene koji se nalaze u regionima gde se su pronađene mutcije statistički značajno povezane sa statusom \"bolesti\".\n","  - Napisati funkciju koja kreira intervalska stabla na osnovu koordinata gena iz entrez tabele. Funkcija treba da vrati mapu čiji su ključevi identifikatori hromozoma (1, 2, 3... ili chr1, chr2, chr3...), a vrednosti stabla sa intervalima gena da datom hromozomu. Možete upotrebiti postojeću biblioteku za intervalska stabla (na primer intervaltree).\n","  - Napisati funkciju koja za svaku grupu iz zadatka 3 određuje gen u kojem se nalazi vodeća mutacija iz grupe.  \n","\n",".\n","\n","6 [4 boda]. Polazeći od gena identifikovanih u zadatku 5 odrediti biološke procese koji su povezani sa posmatranim stanjem. Jednostavan način kojim se ovo može odrediti je na osnovu procenta identifikovanih gena koji su označeni kao da učestvuju nekom procesu: $$score = \\frac{PATHWAY\\_GENES \\cap GROUP\\_GENES}{|GROUP\\_GENES|} $$\n","Verovatno povezane biološke procese možemo odrediti tako što na ovako izračunat rezultat primenimo graničnu vrednost, na primer 0.7.\n","\n",".\n","\n","## Napomene\n","- Oznake hromozoma u VCF fajlu i entrez tabeli nisu direktno kompatibilni. Hromozomi u VCF fajlu su označeni kao chr1, chr2, ..., dok su u entrez tabeli samo brojevi 1, 2, ... Negde u kodu će biti potrebno da ove oznake \"pomirite\" (uklonite ili dodate prefiks chr).\n","- Liste gena povezanih sa procesima u tabeli `kegg_pathways.tsv` su dati kao jedan string, pri čemu su elemnti liste (pojedničani geni) odvojeni zapetom. U zadatku 56 je verovatno najbolje te stringove pretvoriti u liste (`string.split(',')`).\n","- Pravljenje Dataframe strukture u zadatku 1 će verovatno potrajati. Jednom napravljenu strukturu je korisno sačuvati (na primer u vidu feather fajla), kako bi kasnije izbegli ponovno pravljenje.\n","- Ukoliko projekat radite na OS X računaru, a želite da koriste multiprocessing za ubrzavanje izračunavanja, potrebno da izvršite sledći kod:\n","```python\n","import multiprocessing as mp\n","if mp.get_start_method() != 'fork':\n","    mp.set_start_method('fork', force=True)\n","```\n","- Možda je lakše projekat razvijati u notebook okruženju (jupyter ili unutar VS Code-a), pa portovati u .py skriptu (kako bi se izbeglo ponovno učitavanje / izračunavanje u toku rada)\n","- Biblioteka `tqdm` je veoma zgodna za praćenje rada petlji koje se dugo izvršavaju:\n","```python\n","from tqdm.auto import tqdm\n","```"]},{"cell_type":"markdown","metadata":{"id":"q7d8X_mgAsvq"},"source":["## Task 1: Load VCF/BCF file into pandas DataFrame\n","\n","This function loads a VCF/BCF file and converts it to a pandas DataFrame where:\n","- Columns are sample names from the VCF/BCF file\n","- Index is created from chromosome and position (format: \"chr-position\")  \n","- Cell values contain the number of alternative alleles (0, 1, or 2) as uint8\n","- Positions with more than 2 alleles are skipped\n","\n","Expected output: DataFrame with genotype data ready for GWAS analysis"]},{"cell_type":"code","source":["!pip install pysam\n","!pip install intervaltree\n","\n","import pandas as pd\n","import numpy as np\n","import pysam\n","from tqdm.auto import tqdm\n","import multiprocessing as mp\n","from scipy.stats import chi2_contingency\n","from intervaltree import IntervalTree\n","import os, subprocess, shutil\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","def load_bcf_to_dataframe(bcf_file_path):\n","    \"\"\"\n","    Load VCF/BCF file into pandas DataFrame.\n","\n","    Parameters:\n","    bcf_file_path (str): Path to BCF file\n","\n","    Returns:\n","    pd.DataFrame: DataFrame with samples as columns, positions as index,\n","                  containing alternative allele counts (0, 1, 2) as uint8\n","    \"\"\"\n","    bcf_file = pysam.VariantFile(bcf_file_path)\n","    samples = list(bcf_file.header.samples)\n","\n","    genotype_data = []\n","    positions = []\n","\n","    for record in tqdm(bcf_file.fetch(), desc=\"Processing variants\"):\n","        # Skip positions with more than 2 alleles\n","        if len(record.alleles) > 2:\n","            continue\n","\n","        chrom = record.contig\n","        pos = record.pos\n","        position_id = f\"{chrom}-{pos}\"\n","        positions.append(position_id)\n","\n","        # Extract genotype data for all samples\n","        genotypes = []\n","        for sample in samples:\n","            gt = record.samples[sample]['GT']\n","            if gt[0] is None or gt[1] is None:  # Missing data\n","                alt_count = 0\n","            else:\n","                alt_count = sum([1 for allele in gt if allele > 0])\n","            genotypes.append(alt_count)\n","\n","        genotype_data.append(genotypes)\n","\n","    # Create DataFrame\n","    df = pd.DataFrame(genotype_data, index=positions, columns=samples, dtype='uint8')\n","\n","    bcf_file.close()\n","    return df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"33jQ8EUNgWBr","executionInfo":{"status":"ok","timestamp":1756122857297,"user_tz":-120,"elapsed":25385,"user":{"displayName":"Dunja Pantelic","userId":"07985769512101982043"}},"outputId":"33fbd8dd-56b0-4240-b041-30387f24c18e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pysam in /usr/local/lib/python3.12/dist-packages (0.23.3)\n","Requirement already satisfied: intervaltree in /usr/local/lib/python3.12/dist-packages (3.1.0)\n","Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from intervaltree) (2.4.0)\n"]}]},{"cell_type":"markdown","source":["## Task 2: GWAS Analysis Function\n","\n","This function performs Genome-Wide Association Study (GWAS) analysis using:\n","- Chi-square test with Laplace correction (adding 1 to each cell)\n","- Additive genetic model (0, 1, 2 alternative alleles)\n","- Multiprocessing for parallel computation\n","- Bonferroni correction for multiple testing\n","- Optional filtering by significance threshold\n","\n","Expected output: DataFrame with p-values sorted by significance, optionally filtered"],"metadata":{"id":"uYfT4qi8gWBt"}},{"cell_type":"code","source":["def chi_square_test_single_variant(args):\n","    \"\"\"Helper function for parallel processing of single variant\"\"\"\n","    position, genotypes, phenotypes = args\n","\n","    # Create contingency table for additive model\n","    # Rows: phenotype (0=control, 1=case)\n","    # Columns: genotype (0, 1, 2 alternative alleles)\n","    contingency = np.zeros((2, 3), dtype=int)\n","\n","    for i, (genotype, phenotype) in enumerate(zip(genotypes, phenotypes)):\n","        contingency[phenotype, genotype] += 1\n","\n","    # Apply Laplace correction (add 1 to each cell)\n","    contingency += 1\n","\n","    # Perform chi-square test\n","    try:\n","        chi2, p_value, dof, expected = chi2_contingency(contingency)\n","        return position, p_value\n","    except:\n","        return position, 1.0  # Return non-significant p-value if test fails\n","\n","def gwas_analysis(genotype_df, phenotype_series, apply_bonferroni=True, significance_threshold=0.05, n_processes=None):\n","    \"\"\"\n","    Perform GWAS analysis using chi-square test with Laplace correction.\n","\n","    Uses additive genetic model where genotype values (0, 1, 2) represent\n","    the number of alternative alleles.\n","\n","    Parameters:\n","    genotype_df (pd.DataFrame): Genotype data with positions as index, samples as columns\n","    phenotype_series (pd.Series): Phenotype status (0=control, 1=case) with samples as index\n","    apply_bonferroni (bool): Whether to apply Bonferroni correction and filter results\n","    significance_threshold (float): P-value threshold for significance\n","    n_processes (int): Number of processes for parallel computation\n","\n","    Returns:\n","    pd.DataFrame: Results with p-values, sorted by significance\n","    \"\"\"\n","    if n_processes is None:\n","        n_processes = mp.cpu_count()\n","\n","    # Align genotype and phenotype data\n","    common_samples = genotype_df.columns.intersection(phenotype_series.index)\n","    genotype_aligned = genotype_df[common_samples]\n","    phenotype_aligned = phenotype_series[common_samples]\n","\n","    # Prepare data for parallel processing\n","    args_list = []\n","    for position in genotype_aligned.index:\n","        genotypes = genotype_aligned.loc[position].values\n","        phenotypes = phenotype_aligned.values\n","        args_list.append((position, genotypes, phenotypes))\n","\n","    # Parallel processing\n","    with mp.Pool(n_processes) as pool:\n","        results = list(tqdm(\n","            pool.imap(chi_square_test_single_variant, args_list),\n","            total=len(args_list),\n","            desc=\"GWAS analysis\"\n","        ))\n","\n","    # Create results DataFrame\n","    positions, p_values = zip(*results)\n","    results_df = pd.DataFrame({\n","        'p_value': p_values\n","    }, index=positions)\n","\n","    # Sort by p-value\n","    results_df = results_df.sort_values('p_value')\n","\n","    # Apply Bonferroni correction and filter if requested\n","    if apply_bonferroni:\n","        bonferroni_threshold = significance_threshold / len(results_df)\n","        results_df = results_df[results_df['p_value'] < bonferroni_threshold]\n","\n","    return results_df"],"metadata":{"id":"2w04Lo7BQH5R"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Task 3: Group Statistically Significant Mutations\n","\n","This function groups mutations based on:\n","- Squared correlation coefficient (r²) between genotypes (threshold: 0.2)\n","- Physical proximity on the same chromosome (within 600,000 base pairs)\n","- Each mutation belongs to only one group\n","- Groups are formed iteratively, checking all existing groups for each new mutation\n","\n","Expected output: DataFrame with one row per group containing lead mutation, p-value, group statistics"],"metadata":{"id":"q0dSjHptgWBu"}},{"cell_type":"code","source":["def group_significant_mutations(gwas_results, genotype_df, correlation_threshold=0.2, distance_threshold=600000):\n","    \"\"\"\n","    Group statistically significant mutations based on correlation and physical distance.\n","\n","    Parameters:\n","    gwas_results (pd.DataFrame): GWAS results with p-values\n","    genotype_df (pd.DataFrame): Genotype data with positions as index\n","    correlation_threshold (float): Minimum r² threshold for grouping\n","    distance_threshold (int): Maximum distance in base pairs for grouping\n","\n","    Returns:\n","    pd.DataFrame: Groups with lead mutation, statistics, and member lists\n","    \"\"\"\n","    if len(gwas_results) == 0:\n","        return pd.DataFrame()\n","\n","    significant_positions = gwas_results.index.tolist()\n","\n","    # Parse chromosome and position information\n","    def parse_position(pos_str):\n","        parts = pos_str.split('-')\n","        chrom = parts[0]\n","        pos = int(parts[1])\n","        return chrom, pos\n","\n","    # Calculate correlation matrix for significant positions\n","    significant_genotypes = genotype_df.loc[significant_positions]\n","    correlation_matrix = np.corrcoef(significant_genotypes.values) ** 2\n","\n","    # Initialize groups\n","    groups = []\n","    assigned = set()\n","\n","    for i, current_pos in enumerate(tqdm(significant_positions, desc=\"Grouping mutations\")):\n","        if current_pos in assigned:\n","            continue\n","\n","        current_chrom, current_coord = parse_position(current_pos)\n","        current_group = [current_pos]\n","        assigned.add(current_pos)\n","\n","        # Check if current position can be added to any existing group\n","        group_found = False\n","        for group in groups:\n","            can_join_group = False\n","\n","            for member_pos in group:\n","                member_idx = significant_positions.index(member_pos)\n","                member_chrom, member_coord = parse_position(member_pos)\n","\n","                # Check correlation and distance criteria\n","                if (correlation_matrix[i, member_idx] >= correlation_threshold and\n","                    current_chrom == member_chrom and\n","                    abs(current_coord - member_coord) <= distance_threshold):\n","                    can_join_group = True\n","                    break\n","\n","            if can_join_group:\n","                group.extend(current_group)\n","                group_found = True\n","                break\n","\n","        if not group_found:\n","            groups.append(current_group)\n","\n","    # Create results DataFrame\n","    group_results = []\n","    for group in groups:\n","        # Find lead mutation (lowest p-value)\n","        group_p_values = gwas_results.loc[group, 'p_value']\n","        lead_mutation = group_p_values.idxmin()\n","        lead_p_value = group_p_values.min()\n","\n","        # Parse positions and calculate statistics\n","        positions_data = [parse_position(pos) for pos in group]\n","        chromosomes = [chrom for chrom, pos in positions_data]\n","        coords = [pos for chrom, pos in positions_data]\n","\n","        group_results.append({\n","            'lead_mutation': lead_mutation,\n","            'lead_p_value': lead_p_value,\n","            'num_mutations': len(group),\n","            'chromosome': chromosomes[0],  # All should be same chromosome\n","            'min_position': min(coords),\n","            'max_position': max(coords),\n","            'span': max(coords) - min(coords),\n","            'mutations': group\n","        })\n","\n","    results_df = pd.DataFrame(group_results).sort_values('lead_p_value')\n","    return results_df"],"metadata":{"id":"MP5sGqKDQWg5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Task 4 (Bonus): Bayesian Network for Disease Status Prediction\n","\n","This creates and evaluates Bayesian networks for predicting disease status using:\n","1. Genotypes of lead mutations (top 4 groups with lowest p-values)\n","2. Environmental/phenotypic factors from additional file\n","3. Combined genotype and environmental data\n","\n","Evaluation metrics: precision, recall, and accuracy for each network type\n","\n","Expected output: Three trained Bayesian networks with performance metrics"],"metadata":{"id":"7JEv1DLPgWBv"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.metrics import precision_score, recall_score, accuracy_score\n","from sklearn.preprocessing import LabelEncoder\n","\n","def create_bayesian_networks(mutation_groups, genotype_df, phenotype_series, env_factors_file):\n","    \"\"\"\n","    Create and evaluate Bayesian networks for disease status prediction.\n","\n","    Parameters:\n","    mutation_groups (pd.DataFrame): Grouped mutations from task 3\n","    genotype_df (pd.DataFrame): Genotype data\n","    phenotype_series (pd.Series): Disease status\n","    env_factors_file (str): Path to environmental factors TSV file\n","\n","    Returns:\n","    dict: Results with models and performance metrics\n","    \"\"\"\n","    # Load environmental factors\n","    env_factors = pd.read_csv(env_factors_file, sep='\\t', index_col=0)\n","\n","    # Get top 4 lead mutations\n","    if len(mutation_groups) >= 4:\n","        top_mutations = mutation_groups.head(4)['lead_mutation'].tolist()\n","    else:\n","        top_mutations = mutation_groups['lead_mutation'].tolist()\n","\n","    # Prepare datasets\n","    results = {}\n","\n","    # 1. Genotype-only network\n","    if top_mutations:\n","        genotype_features = genotype_df.loc[top_mutations].T\n","        genotype_features.columns = [f'mutation_{i+1}' for i in range(len(top_mutations))]\n","\n","        # Align with phenotype data\n","        common_samples = genotype_features.index.intersection(phenotype_series.index)\n","        X_genotype = genotype_features.loc[common_samples]\n","        y_genotype = phenotype_series.loc[common_samples]\n","\n","        if len(X_genotype) > 0:\n","            results['genotype_only'] = train_and_evaluate_model(X_genotype, y_genotype, 'Genotype-only')\n","\n","    # 2. Environmental factors only network\n","    common_samples_env = env_factors.index.intersection(phenotype_series.index)\n","    if len(common_samples_env) > 0:\n","        X_env = env_factors.loc[common_samples_env]\n","        y_env = phenotype_series.loc[common_samples_env]\n","\n","        # Encode categorical variables if any\n","        X_env_encoded = X_env.copy()\n","        label_encoders = {}\n","        for column in X_env_encoded.columns:\n","            if X_env_encoded[column].dtype == 'object':\n","                le = LabelEncoder()\n","                X_env_encoded[column] = le.fit_transform(X_env_encoded[column].astype(str))\n","                label_encoders[column] = le\n","\n","        results['environmental_only'] = train_and_evaluate_model(X_env_encoded, y_env, 'Environmental-only')\n","\n","    # 3. Combined network\n","    if top_mutations and len(common_samples_env) > 0:\n","        # Find common samples across all datasets\n","        common_all = (genotype_features.index\n","                     .intersection(env_factors.index)\n","                     .intersection(phenotype_series.index))\n","\n","        if len(common_all) > 0:\n","            X_combined = pd.concat([\n","                genotype_features.loc[common_all],\n","                X_env_encoded.loc[common_all]\n","            ], axis=1)\n","            y_combined = phenotype_series.loc[common_all]\n","\n","            results['combined'] = train_and_evaluate_model(X_combined, y_combined, 'Combined')\n","\n","    return results\n","\n","def train_and_evaluate_model(X, y, model_name):\n","    \"\"\"\n","    Train and evaluate a Gaussian Naive Bayes model.\n","\n","    Parameters:\n","    X (pd.DataFrame): Features\n","    y (pd.Series): Target variable\n","    model_name (str): Name for reporting\n","\n","    Returns:\n","    dict: Model and performance metrics\n","    \"\"\"\n","    # Split data\n","    X_train, X_test, y_train, y_test = train_test_split(\n","        X, y, test_size=0.3, random_state=42, stratify=y\n","    )\n","\n","    # Train Gaussian Naive Bayes (approximation of Bayesian Network)\n","    model = GaussianNB()\n","    model.fit(X_train, y_train)\n","\n","    # Make predictions\n","    y_pred = model.predict(X_test)\n","\n","    # Calculate metrics\n","    precision = precision_score(y_test, y_pred, average='binary')\n","    recall = recall_score(y_test, y_pred, average='binary')\n","    accuracy = accuracy_score(y_test, y_pred)\n","\n","    return {\n","        'model': model,\n","        'precision': precision,\n","        'recall': recall,\n","        'accuracy': accuracy,\n","        'model_name': model_name,\n","        'n_features': X.shape[1],\n","        'n_samples': len(X)\n","    }"],"metadata":{"id":"91be8FQgQd8s"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Task 5: Identify Genes in Significant Regions\n","\n","This creates interval trees for gene coordinates and identifies genes containing lead mutations:\n","1. Build interval trees per chromosome from gene coordinate data\n","2. Handle chromosome naming differences (chr1 vs 1)\n","3. Query trees to find genes overlapping with lead mutation positions\n","\n","Expected output: Functions for creating interval trees and finding genes containing mutations"],"metadata":{"id":"tz27M4WwgWBw"}},{"cell_type":"code","source":["def create_gene_interval_trees(entrez_file):\n","    \"\"\"\n","    Create interval trees for gene coordinates from entrez gene table.\n","\n","    Parameters:\n","    entrez_file (str): Path to entrez gene TSV file\n","\n","    Returns:\n","    dict: Chromosome ID -> IntervalTree mapping\n","    \"\"\"\n","    genes_df = pd.read_csv(entrez_file, sep='\\t')\n","\n","    # Create interval trees for each chromosome\n","    chromosome_trees = {}\n","\n","    for _, gene in genes_df.iterrows():\n","        chrom = str(gene['chromosome'])\n","        start = gene['start']\n","        end = gene['end']\n","        gene_id = gene['gene_id']\n","        gene_symbol = gene.get('gene_symbol', f'Gene_{gene_id}')\n","\n","        # Normalize chromosome naming (remove 'chr' prefix if present)\n","        if chrom.startswith('chr'):\n","            chrom = chrom[3:]\n","\n","        # Create tree for chromosome if it doesn't exist\n","        if chrom not in chromosome_trees:\n","            chromosome_trees[chrom] = IntervalTree()\n","\n","        # Add gene interval to tree (store gene info as data)\n","        chromosome_trees[chrom][start:end+1] = {\n","            'gene_id': gene_id,\n","            'gene_symbol': gene_symbol,\n","            'start': start,\n","            'end': end\n","        }\n","\n","    return chromosome_trees\n","\n","def find_genes_for_mutations(mutation_groups, chromosome_trees):\n","    \"\"\"\n","    Find genes containing lead mutations from each group.\n","\n","    Parameters:\n","    mutation_groups (pd.DataFrame): Grouped mutations from task 3\n","    chromosome_trees (dict): Chromosome interval trees from create_gene_interval_trees\n","\n","    Returns:\n","    pd.DataFrame: Mutation groups with associated gene information\n","    \"\"\"\n","    def parse_position(pos_str):\n","        parts = pos_str.split('-')\n","        chrom = parts[0]\n","        pos = int(parts[1])\n","        return chrom, pos\n","\n","    def normalize_chromosome(chrom):\n","        # Remove 'chr' prefix to match entrez table format\n","        if chrom.startswith('chr'):\n","            return chrom[3:]\n","        return chrom\n","\n","    results = []\n","\n","    for _, group in mutation_groups.iterrows():\n","        lead_mutation = group['lead_mutation']\n","        chrom, pos = parse_position(lead_mutation)\n","        norm_chrom = normalize_chromosome(chrom)\n","\n","        # Find overlapping genes\n","        overlapping_genes = []\n","        if norm_chrom in chromosome_trees:\n","            overlaps = chromosome_trees[norm_chrom][pos]\n","            for interval in overlaps:\n","                gene_info = interval.data\n","                overlapping_genes.append(gene_info)\n","\n","        # Create result entry\n","        result = group.to_dict()\n","        if overlapping_genes:\n","        # If multiple genes overlap, take the first one\n","            # (in practice, this is rare for point mutations)\n","            gene_info = overlapping_genes[0]\n","            result['gene_id'] = gene_info['gene_id']\n","            result['gene_symbol'] = gene_info['gene_symbol']\n","            result['gene_start'] = gene_info['start']\n","            result['gene_end'] = gene_info['end']\n","        else:\n","            result['gene_id'] = None\n","            result['gene_symbol'] = None\n","            result['gene_start'] = None\n","            result['gene_end'] = None\n","\n","        result['num_overlapping_genes'] = len(overlapping_genes)\n","        results.append(result)\n","        return pd.DataFrame(results)"],"metadata":{"id":"s5ox2o4MQluX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Task 6: Biological Process Analysis\n","\n","This identifies biological processes connected to genes from significant mutation regions:\n","1. Load KEGG pathway data and parse gene lists (comma-separated strings)\n","2. Calculate overlap score: (pathway_genes ∩ identified_genes) / |identified_genes|\n","3. Apply threshold (e.g., 0.7) to identify likely connected biological processes\n","\n","Expected output: Function to analyze pathway enrichment and identify relevant biological processes"],"metadata":{"id":"Il_lpWG1gWBx"}},{"cell_type":"code","source":["def analyze_biological_processes(genes_with_mutations, kegg_pathways_file, score_threshold=0.7):\n","    \"\"\"\n","    Identify biological processes connected to identified genes.\n","\n","    Parameters:\n","    genes_with_mutations (pd.DataFrame): Results from find_genes_for_mutations\n","    kegg_pathways_file (str): Path to KEGG pathways TSV file\n","    score_threshold (float): Minimum overlap score for pathway significance\n","\n","    Returns:\n","    pd.DataFrame: Pathways with overlap scores above threshold\n","    \"\"\"\n","    # Load KEGG pathways\n","    pathways_df = pd.read_csv(kegg_pathways_file, sep='\\t')\n","\n","    # Extract identified genes (exclude None values)\n","    identified_genes = set()\n","    for _, row in genes_with_mutations.iterrows():\n","        if pd.notna(row['gene_id']):\n","            identified_genes.add(str(row['gene_id']))\n","        if pd.notna(row['gene_symbol']):\n","            identified_genes.add(str(row['gene_symbol']))\n","\n","    if not identified_genes:\n","        print(\"No genes identified from mutations\")\n","        return pd.DataFrame()\n","\n","    print(f\"Analyzing {len(identified_genes)} identified genes: {identified_genes}\")\n","\n","    # Analyze each pathway\n","    pathway_results = []\n","\n","    for _, pathway in pathways_df.iterrows():\n","        pathway_id = pathway.get('pathway_id', pathway.get('pathway', 'Unknown'))\n","        pathway_name = pathway.get('pathway_name', pathway.get('description', 'Unknown'))\n","        genes_str = pathway.get('genes', pathway.get('gene_list', ''))\n","\n","        if pd.isna(genes_str) or genes_str == '':\n","            continue\n","\n","        # Parse gene list (comma-separated)\n","        pathway_genes = set([gene.strip() for gene in str(genes_str).split(',') if gene.strip()])\n","\n","        if not pathway_genes:\n","            continue\n","\n","        # Calculate overlap\n","        overlap_genes = identified_genes.intersection(pathway_genes)\n","        overlap_count = len(overlap_genes)\n","\n","        # Calculate score\n","        score = overlap_count / len(identified_genes) if identified_genes else 0\n","\n","        pathway_results.append({\n","            'pathway_id': pathway_id,\n","            'pathway_name': pathway_name,\n","            'overlap_score': score,\n","            'overlap_count': overlap_count,\n","            'identified_genes_count': len(identified_genes),\n","            'pathway_genes_count': len(pathway_genes),\n","            'overlapping_genes': list(overlap_genes),\n","            'all_pathway_genes': list(pathway_genes)\n","        })\n","\n","    # Create results DataFrame\n","    results_df = pd.DataFrame(pathway_results)\n","\n","    if len(results_df) == 0:\n","        print(\"No pathway results generated\")\n","        return pd.DataFrame()\n","\n","    # Filter by threshold and sort by score\n","    significant_pathways = results_df[results_df['overlap_score'] >= score_threshold].copy()\n","    significant_pathways = significant_pathways.sort_values('overlap_score', ascending=False)\n","\n","    print(f\"Found {len(significant_pathways)} pathways above threshold {score_threshold}\")\n","\n","    return significant_pathways\n","\n","def print_pathway_analysis_summary(pathway_results, genes_with_mutations):\n","    \"\"\"\n","    Print a summary of the pathway analysis results.\n","\n","    Parameters:\n","    pathway_results (pd.DataFrame): Results from analyze_biological_processes\n","    genes_with_mutations (pd.DataFrame): Gene information from mutations\n","    \"\"\"\n","    print(\"\\\\n\" + \"=\"*60)\n","    print(\"BIOLOGICAL PROCESS ANALYSIS SUMMARY\")\n","    print(\"=\"*60)\n","\n","    # Summary of identified genes\n","    identified_genes = []\n","    for _, row in genes_with_mutations.iterrows():\n","        if pd.notna(row['gene_symbol']):\n","            identified_genes.append(row['gene_symbol'])\n","        elif pd.notna(row['gene_id']):\n","            identified_genes.append(str(row['gene_id']))\n","\n","    print(f\"\\\\nIdentified genes from significant mutations: {len(set(identified_genes))}\")\n","    print(f\"Genes: {', '.join(set(identified_genes))}\")\n","\n","    # Summary of pathway results\n","    if len(pathway_results) > 0:\n","        print(f\"\\\\nSignificant biological processes: {len(pathway_results)}\")\n","        print(\"\\\\nTop pathways:\")\n","        for _, pathway in pathway_results.head(10).iterrows():\n","            print(f\"  - {pathway['pathway_name']} (score: {pathway['overlap_score']:.3f})\")\n","    else:\n","        print(\"\\\\nNo significant biological processes identified.\")\n","\n","    print(\"=\"*60)"],"metadata":{"id":"Qs1qETiOQsr8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Main Analysis Pipeline\n","\n","This section demonstrates how to run the complete analysis pipeline with all implemented functions.\n","The pipeline loads data, performs GWAS analysis, groups mutations, identifies genes, and analyzes biological processes.\n","\n","Expected workflow: Complete bioinformatics analysis from BCF file to biological insights"],"metadata":{"id":"Qk5jVEW5gWBx"}},{"cell_type":"code","source":["# Main analysis pipeline\n","def run_complete_analysis():\n","    \"\"\"\n","    Run the complete bioinformatics analysis pipeline.\n","    \"\"\"\n","    base_drive = None\n","    try:\n","        from google.colab import drive\n","        drive.mount('/content/drive', force_remount=False)\n","        base_drive = \"/content/drive/MyDrive/bioinformatika\"\n","    except Exception:\n","        pass\n","\n","\n","    def first_existing(*paths):\n","        for p in paths:\n","            if p and os.path.exists(p):\n","                return p\n","        return None\n","\n","\n","    bcf_file = first_existing(\"1KG.subset.bcf\",\n","                              f\"{base_drive}/1KG.subset.bcf\" if base_drive else None)\n","    disease_file = first_existing(\"disease.tsv\",\n","                                  f\"{base_drive}/disease.tsv\" if base_drive else None)\n","    env_factors_file = first_existing(\"env_factors.tsv\",\n","                                      f\"{base_drive}/env_factors.tsv\" if base_drive else None)\n","    entrez_file = first_existing(\"entrez.hg38.tsv\",\n","                                 f\"{base_drive}/entrez.hg38.tsv\" if base_drive else None)\n","    kegg_file = first_existing(\"kegg_pathways.tsv\",\n","                               f\"{base_drive}/kegg_pathways.tsv\" if base_drive else None)\n","\n","\n","    missing = { \"BCF\": bcf_file, \"disease\": disease_file, \"env_factors\": env_factors_file,\n","                \"entrez\": entrez_file, \"kegg\": kegg_file }\n","    not_found = [k for k,v in missing.items() if v is None]\n","    if not_found:\n","        raise FileNotFoundError(\n","            \"Nisam našao sledeće fajlove (ni lokalno ni na Drive-u /MyDrive/bioinformatika): \"\n","            + \", \".join(not_found)\n","        )\n","\n","    print(\"Starting complete bioinformatics analysis pipeline...\")\n","    print(\"=\"*60)\n","\n","    # Task 1: Load BCF file\n","    print(\"\\\\n1. Loading BCF file...\")\n","    genotype_df = load_bcf_to_dataframe(bcf_file)\n","    print(f\"Loaded genotype data: {genotype_df.shape[0]} variants, {genotype_df.shape[1]} samples\")\n","\n","    # Save genotype data for future use\n","    # genotype_df.to_feather(\"genotype_data.feather\")\n","\n","    # Load phenotype data\n","    print(\"\\\\n2. Loading phenotype data...\")\n","    phenotype_df = pd.read_csv(disease_file, sep='\\\\t', index_col=0)\n","    phenotype_series = phenotype_df.iloc[:, 0]  # Assuming first column is disease status\n","    print(f\"Loaded phenotype data: {len(phenotype_series)} samples\")\n","\n","    # Task 2: GWAS analysis\n","    print(\"\\\\n3. Performing GWAS analysis...\")\n","    gwas_results = gwas_analysis(genotype_df, phenotype_series)\n","    print(f\"GWAS completed: {len(gwas_results)} significant associations found\")\n","\n","    if len(gwas_results) > 0:\n","        # Task 3: Group mutations\n","        print(\"\\\\n4. Grouping significant mutations...\")\n","        mutation_groups = group_significant_mutations(gwas_results, genotype_df)\n","        print(f\"Formed {len(mutation_groups)} mutation groups\")\n","\n","        # Task 5: Identify genes\n","        print(\"\\\\n5. Identifying genes in significant regions...\")\n","        chromosome_trees = create_gene_interval_trees(entrez_file)\n","        genes_with_mutations = find_genes_for_mutations(mutation_groups, chromosome_trees)\n","        print(f\"Identified genes for {len(genes_with_mutations)} groups\")\n","\n","        # Task 6: Biological process analysis\n","        print(\"\\\\n6. Analyzing biological processes...\")\n","        pathway_results = analyze_biological_processes(genes_with_mutations, kegg_file)\n","        print_pathway_analysis_summary(pathway_results, genes_with_mutations)\n","\n","        # Task 4: Bayesian networks\n","        print(\"\\\\n7. Creating Bayesian networks (bonus task)...\")\n","        try:\n","            bn_results = create_bayesian_networks(mutation_groups, genotype_df, phenotype_series, env_factors_file)\n","            print(\"\\\\nBayesian Network Results:\")\n","            for model_type, results in bn_results.items():\n","                print(f\"  {results['model_name']}:\")\n","                print(f\"    Precision: {results['precision']:.3f}\")\n","                print(f\"    Recall: {results['recall']:.3f}\")\n","                print(f\"    Accuracy: {results['accuracy']:.3f}\")\n","        except Exception as e:\n","            print(f\"Bayesian networks failed: {e}\")\n","\n","        print(\"\\\\n\" + \"=\"*60)\n","        print(\"Analysis completed successfully!\")\n","        print(\"=\"*60)\n","\n","        return {\n","            'genotype_df': genotype_df,\n","            'gwas_results': gwas_results,\n","            'mutation_groups': mutation_groups,\n","            'genes_with_mutations': genes_with_mutations,\n","            'pathway_results': pathway_results\n","        }\n","    else:\n","        print(\"No significant associations found. Analysis stopped.\")\n","        return None\n","\n","\n","results = run_complete_analysis()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":118,"referenced_widgets":["9c17f4ba13944acda3fc2b1cecbc57ed","d4dc425ff4e34e6e95e6a48b67482ad8","b10a9aa52e2c47ba8b8af719f73b9081","21c8f3a9d1ae4b4b85f4f5df29306fed","73df3e6a7aa24af397dea1acf70ce73f","5c80fd461598448aa943c0be103e905b","a6da2f44a4e7422e802bf1fc3997b820","f3bd0cb039d0412dbe7c1d59bf363c9a","444b5ad1a458465cb5737d7c78340283","6fccae08cfc14a509bfdaae4b72d21ca","1005718cfb494539ad6356811aa464e7"]},"id":"A55cKXTZQ1zS","outputId":"8fbcb007-8428-4cf1-f21c-982ed577874c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Starting complete bioinformatics analysis pipeline...\n","============================================================\n","\\n1. Loading BCF file...\n"]},{"output_type":"display_data","data":{"text/plain":["Processing variants: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c17f4ba13944acda3fc2b1cecbc57ed"}},"metadata":{}}]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"bio","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.13.2"},"widgets":{"application/vnd.jupyter.widget-state+json":{"9c17f4ba13944acda3fc2b1cecbc57ed":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d4dc425ff4e34e6e95e6a48b67482ad8","IPY_MODEL_b10a9aa52e2c47ba8b8af719f73b9081","IPY_MODEL_21c8f3a9d1ae4b4b85f4f5df29306fed"],"layout":"IPY_MODEL_73df3e6a7aa24af397dea1acf70ce73f"}},"d4dc425ff4e34e6e95e6a48b67482ad8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5c80fd461598448aa943c0be103e905b","placeholder":"​","style":"IPY_MODEL_a6da2f44a4e7422e802bf1fc3997b820","value":"Processing variants: "}},"b10a9aa52e2c47ba8b8af719f73b9081":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"info","description":"","description_tooltip":null,"layout":"IPY_MODEL_f3bd0cb039d0412dbe7c1d59bf363c9a","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_444b5ad1a458465cb5737d7c78340283","value":1}},"21c8f3a9d1ae4b4b85f4f5df29306fed":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6fccae08cfc14a509bfdaae4b72d21ca","placeholder":"​","style":"IPY_MODEL_1005718cfb494539ad6356811aa464e7","value":" 274/? [00:01&lt;00:00, 164.57it/s]"}},"73df3e6a7aa24af397dea1acf70ce73f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c80fd461598448aa943c0be103e905b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a6da2f44a4e7422e802bf1fc3997b820":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f3bd0cb039d0412dbe7c1d59bf363c9a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"444b5ad1a458465cb5737d7c78340283":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6fccae08cfc14a509bfdaae4b72d21ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1005718cfb494539ad6356811aa464e7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}